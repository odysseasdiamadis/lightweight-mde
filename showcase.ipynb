{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7682e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data/nyu/nyu_data/data\n"
     ]
    }
   ],
   "source": [
    "from data import NYUDataset, RescaleDepth\n",
    "import yaml\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import yaml\n",
    "import os\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import v2 as t\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import VisionDataset\n",
    "\n",
    "from architecture import build_METER_model\n",
    "from metrics import REL, RMSE, delta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_config(config_path):\n",
    "    \"\"\"Load configuration from YAML file.\"\"\"\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "config = load_config('./config.yaml')\n",
    "\n",
    "dataset = NYUDataset(\n",
    "    root=config['data']['root'],\n",
    "    test=True,\n",
    ")\n",
    "dataloader = DataLoader(dataset, 128)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cac649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import Tensor\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def tensor_to_image(x: Tensor, rgb=False):\n",
    "    # np_image = x.permute(0, 1).numpy()\n",
    "    if x.get_device() >= 0:\n",
    "        x = x.cpu()\n",
    "\n",
    "    if rgb:\n",
    "        x = x.permute((1, 2, 0))\n",
    "    \n",
    "    np_image = x.numpy()\n",
    "    # 3. Convert to uint8 (for displaying as an image)\n",
    "    np_image = (np_image).astype(np.uint8)\n",
    "\n",
    "    # 4. Create PIL Image\n",
    "    pil_image = Image.fromarray(np_image, \"RGB\" if rgb else None)\n",
    "\n",
    "    # 5. Display using matplotlib inline in notebook\n",
    "    if rgb:\n",
    "        plt.imshow(pil_image)\n",
    "    else:\n",
    "        plt.imshow(pil_image, vmin=0, vmax=1000)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fea19d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_nth_dataset(model, dataset, n):\n",
    "    img, depth = dataset[n]\n",
    "    img = img.unsqueeze(0).to(device=\"cuda\")\n",
    "    depth = depth.unsqueeze(0).to(device=\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        output = model(img)\n",
    "    print(img.shape)\n",
    "    print(depth.shape)\n",
    "    print(output.shape)\n",
    "    tensor_to_image((img).squeeze(dim=(0,1)), True)\n",
    "    tensor_to_image((depth).squeeze(dim=(0,1)))\n",
    "    tensor_to_image((output).squeeze(dim=(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a9b5883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1.)\n",
      "tensor(0.2000)\n"
     ]
    }
   ],
   "source": [
    "from metrics import *\n",
    "\n",
    "BATCH = 128\n",
    "\n",
    "# Test case: Perfect prediction\n",
    "pred = torch.ones(BATCH, 1, 192, 256) * 5.0  # 5m depth everywhere\n",
    "target = torch.ones(BATCH, 1, 192, 256) * 5.0\n",
    "\n",
    "print(RMSE(pred, target))  # Should be 0.0\n",
    "print(REL(pred, target))   # Should be 0.0\n",
    "print(delta(pred, target)) # Should be 1.0\n",
    "\n",
    "# Test case: Off by 1m\n",
    "pred = torch.ones(BATCH, 1, 192, 256) * 6.0\n",
    "print(REL(pred, target))   # Should be 0.2 (|6-5|/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "646d2089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load_checkpoint\n",
    "\n",
    "\n",
    "model = build_METER_model(\"cuda\", \"s\")\n",
    "model = model.to(\"cuda\")\n",
    "x = load_checkpoint(model, './models/build_model_best_nyu_s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4859926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_out 457.4888000488281\n",
      "max_data 995.2000122070312\n",
      "min_out 146.2028350830078\n",
      "min_data 71.30000305175781\n"
     ]
    }
   ],
   "source": [
    "max_out = -1\n",
    "max_data = -1\n",
    "min_out = 10000\n",
    "min_data = 10000\n",
    "for r, d in dataloader:\n",
    "    max_data = max(max_data, torch.max(d).float().item())\n",
    "    min_data = min(min_data, torch.min(d).float().item())\n",
    "    with torch.no_grad():\n",
    "        output = model(dataset[0][0].unsqueeze(0).to(device=\"cuda\"))\n",
    "    max_out = max(max_out, torch.max(output).float().item())\n",
    "    min_out = min(min_out, torch.min(output).float().item())\n",
    "print(\"max_out\", max_out)\n",
    "print(\"max_data\", max_data)\n",
    "print(\"min_out\", min_out)\n",
    "print(\"min_data\", min_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a5069c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:10<00:00,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE            88.229588\n",
      "REL              0.240335\n",
      "delta            0.477409\n",
      "loss_depth      71.435059\n",
      "loss_grad      210.197385\n",
      "loss_normal     36.093906\n",
      "loss_ssim       19.531841\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from loss import balanced_loss_function\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module, dataloader, criterion, device):\n",
    "    \"\"\"Validate for one epoch.\"\"\"\n",
    "    model.eval()\n",
    "    total_samples = 0\n",
    "\n",
    "    metrics = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(dataloader, desc=\"Validation\")\n",
    "        \n",
    "        for images, targets in progress_bar:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            metrics.append({\n",
    "                \"RMSE\": RMSE(outputs, targets).item(),\n",
    "                \"REL\": REL(outputs, targets).item(),\n",
    "                \"delta\": delta(outputs, targets).item(),\n",
    "                \"loss_depth\": loss[0].item(),\n",
    "                \"loss_grad\": loss[1].item(),\n",
    "                \"loss_normal\": loss[2].item(),\n",
    "                \"loss_ssim\": loss[3].item(),\n",
    "            })\n",
    "            \n",
    "            batch_size = images.size(0)\n",
    "            total_samples += batch_size\n",
    "\n",
    "    return metrics\n",
    "\n",
    "metrics = evaluate(model, dataloader, balanced_loss_function(device=\"cuda\", dtype=torch.float32), \"cuda\")\n",
    "df = pd.DataFrame(metrics).mean()\n",
    "df.to_csv(\"./metrics.csv\")\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
